.\" generated with Ronn/v0.7.3
.\" http://github.com/rtomayko/ronn/tree/0.7.3
.
.TH "CRAWLER" "1" "March 2017" "IBM " "IBM Data Crawler Manual"
.
.SH "NAME"
\fBcrawler\fR \- A crawler to move data from point A to point B
.
.SH "SYNOPSIS"
Usage: crawler [ crawl | testit | restart | resume | refresh ] [ options ]
.
.SH "DESCRIPTION"
The Data Crawler is used to crawl various repositories of data, such as content management systems and filesystems, and then push the resulting documents to a remote service\.
.
.SH "GLOBAL OPTIONS"
.
.nf

\-\-version
    Displays program version
\-\-help
    Displays this usage text
.
.fi
.
.SH "COMMANDS"
.
.SS "crawl [ options ]"
Runs a crawl with the current configuration\.
.
.IP "" 4
.
.nf

\-c <value> | \-\-config <value>  # Specifies the configuration file to use\. Default is "config/crawler\.conf"\.
\-\-pii\-checking <value>         # Toggles PII checking
.
.fi
.
.IP "" 0
.
.SS "testit [ options ]"
Runs a test crawl, which crawls only the seed URL and displays any enqueued URLs\. If the seed URL results in indexable content (e\.g\., it is a document), then that content is sent to the output adapter and the content is printed to the screen\. If the seed URL retrieval causes URLs to be enqueued, those URLs will be displayed, and no content will be sent to the output adapter\. By default, five enqueued URLs are displayed\.
.
.IP "" 4
.
.nf

\-c <value> | \-\-config <value>  # Specifies the configuration file to use\. Default is "config/crawler\.conf"\.
\-l <n> | \-\-limit <n>           # Limits the number of enqueued URLs that are displayed\.
\-\-pii\-checking <value>         # Toggles PII checking
.
.fi
.
.IP "" 0
.
.SS "restart [ options ]"
Runs a Restart crawl; starts a new crawl with the current configuration\.
.
.IP "" 4
.
.nf

\-c <value> | \-\-config <value>  # Specifies the configuration file to use\.
\-\-pii\-checking <value>         # Toggles PII checking
.
.fi
.
.IP "" 0
.
.SS "resume [ options ]"
Resumes a crawl from where it stopped\.
.
.IP "" 4
.
.nf

\-c <value> | \-\-config <value>  # Specifies the configuration file to use\.
\-\-pii\-checking <value>         # Toggles PII checking
.
.fi
.
.IP "" 0
.
.SS "refresh [ options ]"
Refreshes a previous crawl\.
.
.IP "" 4
.
.nf

\-c <value> | \-\-config <value>  # Specifies the configuration file to use\.
\-\-pii\-checking <value>         # Toggles PII checking
.
.fi
.
.IP "" 0
.
.SH "EXAMPLES"
Run a crawl using the configuration file at \fBconfig/crawler\.conf\fR:
.
.IP "" 4
.
.nf

crawler crawl
.
.fi
.
.IP "" 0
.
.P
Run a test using the configuration file at \fBconfig/crawler\.conf\fR:
.
.IP "" 4
.
.nf

crawler testit
.
.fi
.
.IP "" 0
.
.P
Run a crawl using the configuration file at \fB/home/watson/office\-share\.conf\fR:
.
.IP "" 4
.
.nf

crawler crawl \-\-config /home/watson/office\-share\.conf
.
.fi
.
.IP "" 0
.
.P
Display usage, including version:
.
.IP "" 4
.
.nf

crawler \-\-help
.
.fi
.
.IP "" 0
.
.SH "CONFIGURATION"
\fBcrawler\fR requires a configuration file for its options\. Examples of configuration files are provided in the \fBshare\fR directory within \fBcrawler\fR\'s installation directory\. Copy these examples and modify them\. \fIDo not modify the examples in place\.\fR
.
.P
Without specifying the \fB\-\-config | \-c\fR option, \fBcrawler\fR will look for its configuration in the \fBconfig\fR directory of the directory in which \fBcrawler\fR is started\. That is, \fBcrawler\fR will look for \fBconfig/crawler\.conf\fR\.
.
.SH "DIAGNOSTICS"
Use these features to diagnose problems\.
.
.SS "Debugging"
Activates debugging mode\. In the \fBcrawler\.conf\fR file, set:
.
.IP "" 4
.
.nf

debugging\.full_node_debugging = true
.
.fi
.
.IP "" 0
.
.SS "Logging"
Enables logging\. In the \fBlog4j_custom\.properties\fR file, set:
.
.IP "" 4
.
.nf

log4j\.rootLogger=INFO, Console, Log
.
.fi
.
.IP "" 0
.
.P
This is the default logging level for file output\. For the console log, the default is:
.
.IP "" 4
.
.nf

log4j\.appender\.Console\.Threshold=WARN
.
.fi
.
.IP "" 0
.
.P
Logging levels may be set to the following values:
.
.IP "" 4
.
.nf

OFF \- The highest possible rank, this is intended to turn off logging\.
FATAL \- Desginates very severe error events that will presumably lead the application to abort\.
ERROR \- Designates error events that may still allow the application to continue running\.
WARN \- Designates potentially harmful situations\.
INFO \- Designates informational messages highlighting the progress of the application at a coarse\-grained level\.
DEBUG \- Designates fine\-grained informational events that are most useful to debug an application\.
TRACE \- Designates finer\-grained informational events than DEBUG\.
ALL \- The lowest possible rank, this is intended to turn on all logging\.
.
.fi
.
.IP "" 0
.
.SH "THROTTLING"
Defines sizing limitations, to help manage throughput\. In the \fBcrawler\.conf\fR file, set:
.
.P
\fBshutdown_timeout\fR Specifies the timeout value, in minutes, before shutting down the application; the default value is 10\.
.
.IP "" 4
.
.nf

shutdown_timeout = <n>
.
.fi
.
.IP "" 0
.
.P
\fBoutput_limit\fR is the highest number of indexable items that the portable crawler will send simultaneously to the output adapter, awaiting a return; the default value is 10\. This may be further limited by cores available to do work\.
.
.IP "" 4
.
.nf

output_limit = <n>
.
.fi
.
.IP "" 0
.
.P
\fBinput_limit\fR Limits the number of URLs that can be requested from the connector at one time; the default value is 3\.
.
.IP "" 4
.
.nf

input_limit = <n>
.
.fi
.
.IP "" 0
.
.P
\fBoutput_timeout\fR is the amount of time, in seconds, before the portable crawler gives up on a request to the output adapter, and then removes the item from the limit queue, to allow more processing\. The default value is 150\.
.
.IP "" 4
.
.nf

output_timeout = <n>
.
.fi
.
.IP "" 0
.
.P
Consideration should be given to the constraints imposed by the output adapter as those constraints may relate to the limits defined here\. The \fBoutput_limit\fR defined above only relates to how many indexable objects can be sent to the output adapter at once\. Once an indexable object is sent to the output adapter, it is "on the clock," as defined by the \fBoutput_timeout\fR variable\. It is possible that the output adapter itself has a throttle preventing it from being able to process as many inputs as it receives\. For instance, the orchestration output adapter may have a connection pool, configurable for HTTP connections to the service\. If it defaults to 8, for example, and if you set the \fBoutput_limit\fR to a number greater than what is configured for that connection pool, then you will have processes, on the clock, waiting for a turn to execute\. You may then experience timeouts\.
.
.P
\fBnum_threads\fR The number of parallel threads that can be run at one time\. This value can be either an integer, which specifies the number of parallel threads directly, or it can be a string, with the format \fB"xNUM"\fR, specifying the multiplication factor of the number of available processors\. The default value is "x1\.5", or 1\.5 times the number of available processors (as taken with \fBRuntime\.availableProcessors\fR)\.
.
.IP "" 4
.
.nf

num_threads = <n>
.
.fi
.
.IP "" 0
.
.P
The formula for calculating parallelism in the Data Crawler pool is: \fBmin(maxThreads, max(minThreads, numThreads))\fR\.
.
.SH "ENVIRONMENT VARIABLE CRAWLER_OPTS"
Following are properties that can be passed to \fBcrawler\fR via the \fBCRAWLER_OPTS\fR environment variable, listed with default values\.
.
.P
Pass them like so:
.
.IP "" 4
.
.nf

CRAWLER_OPTS="\-Dproperty=value \-Dproperty=value" crawler
.
.fi
.
.IP "" 0
.
.P
These should only be changed for debugging, and only under the direction of IBM Support\.
.
.SS "cfa\.java_bin"
\fBcfa\.java_bin\fR can change the \fBjava\fR command used to start the Connector Framework Input Adapter\. By default, \fBcrawler\fR uses the same \fBjava\fR binary that is used to launch \fBcrawler\fR itself\.
.
.P
This can also be changed by setting the \fBjava\.home\fR property, which will then be used to calculate the path to the \fBjava\fR executable\.
.
.SS "cfa\.lib_dir"
\fBcfa\.lib_dir\fR changes the path to the Connector Framework\'s \fBlib\fR directory\. This should rarely need to be changed\. By default, \fBcrawler\fR uses the \fBlib\fR directory inside the calculated path to the Connector Framework, generally simply \fBconnectorFramework\fR\.
.
.SS "cfa\.framework_jars_dir"
\fBcfa\.framework_jars_dir\fR changes the path to the Connector Framework\'s jars directory, which is, by default, in \fBconnectorFramework/<version>/lib/java\fR\.
.
.SS "cfa\.plugins_dir"
\fBcfa\.plugins_dir\fR specifies the path to the Connector Framework\'s plugins directory, where the actual Connectors are stored\. By default, this is built from the \fBframework_jars_dir\fR and will be \fBconnectorFramework/<version>/lib/java/plugins\fR\.
.
.SH "KNOWN LIMITATIONS"
Details known limitations in the current release of the Data Crawler
.
.IP "\(bu" 4
The Data Crawler may hang when running the Filesystem connector with an invalid or missing URL\.
.
.IP "\(bu" 4
Configure the \fBurls_to_filter\fR value in the \fBconfig/crawler\.conf\fR file such that all the whitelist URLs or RegExes are included in a single RegEx expression\.
.
.IP "\(bu" 4
The path to the configuration file passed in the \fB\-\-config | \-c\fR option must be a qualified path\. That is, it must be in the relative formats \fBconfig/crawler\.conf\fR or \fB\./crawler\.conf\fR, or absolute path \fB/path/to/config/crawler\.conf\fR\. Specifying just \fBcrawler\.conf\fR is possible if and only if files referenced using \fBinclude\fR in the \fBcrawler\.conf\fR file are in\-lined instead of using \fBinclude\fR\. For example, \fBdiscovery/discovery_service\.conf\fR is \fBinclude\fR\'d in order to make configuration easier to read\. Its content must be copied into \fBcrawler\.conf\fR within the \fBoutput_adapter\.discovery_service\fR key in order to use an unqualified path in the config option\.
.
.IP "" 0
.
.SH "CHANGE LOG"
See the \fBchangelog\.txt\fR file in your installation directory for a list of changes in this release\.
.
.SH "AUTHOR"
IBM Watson \- https://www\.ibm\.com/smarterplanet/us/en/ibmwatson/
.
.P
Made by yinz in Pittsburgh\.
.
.SH "SEE ALSO"
vcrypt(1)
.
.P
crawler\.conf(5)
.
.P
crawler\-options\.conf(5)
.
.P
crawler\-seed\.conf(5)
.
.P
orchestration_service\.conf(5)
